\section{Discussion}\label{sec:discussion}

In this section, the results of the experiments, as mentioned earlier, will be discussed, and problems with the current experimental setup and points for improvement, as well as opportunities for further research, will be addressed.

\subsection{Uncertainty quantification}

The results from the first experiment, as seen in figure \ref{fig:histogram}, showed that the model predicts high variance on incorrect classifications, with the highest variances pointing towards random guessing of the model. This observation allows for an interesting implementation of a sanity check for the model. This applies not only to these specific EEG classification models but to classification models in general. Moreover, it can even be extended beyond classification tasks when using a different noise-capturing method. One could put a threshold on the maximum variance, which is allowed in a prediction. All classifications with a predicted variance below this threshold are accepted, whereas all classifications with a variance exceeding this threshold are rejected. This method can drastically improve the accuracy of the model. However, this does come at the cost of rejecting some classifications, which would have to be resolved manually. This can be a worthwhile trade-off for classification tasks in which false positives and negatives must be avoided at all costs, such as medical classifications and diagnoses.

The experiment in which the labels were shuffled (Figure \ref{fig:label_shuffle}) showed an increase in the predicted variance as the percentage of labels shuffled increased. In the general noise experiment (Figure \ref{fig:general}), it was observed that the addition of noise, in the form of Gaussian noise and the zeroing of channels, on the entire length of the signal results in an increase in variance. These two experiments indicate that the model behaves as expected, actively basing its variance prediction on the data quality and captures the artificially added noise as uncertainty in the variance output head.

The results from the localized noise experiment, seen in figure \ref{fig:local}, show that the noise location affects the predicted variance, with noise on the 250-500ms region resulting in higher variance and lower accuracy than noise on the 0-250ms region. However, this difference is small. Smaller than one might expect, with the majority of prominent features of the ErrP signal being located in this region. However, previous research shows that this small difference was to be expected. Experiments with varying lengths of the input windows showed that there was only a $6\%$ increase in accuracy when increasing the window from $300$ms to $600$ms after the event's presentation \citep{correia2021error}. Thus, the model was already capable of predicting the label reasonably accurately. However, the slight difference in accuracy and variance between noise in the two regions does suggest that the model shifts its attention to the $250-500$ ms region when it has access to it since noise in this range has a stronger effect. This behaviour aligns with the expectations of this region's prominent features of the Error-related potential.

From the localized and global noise experiment, one can observe that the type of noise added to the signal matters in the variance and accuracy of the model. This behaviour is to be expected. Zeroing has a larger effect since the zeroed signal does not resemble the original signal, and thus the original signal cannot still affect the model. In Gaussian noise, the signal still resembles the original signal, regardless of the intensity of the noise. The original signal will still affect the model.  

\subsection{Uncertainty traceability}

The results of the fourth and final experiment on the traceability of the noise using Shapley values shows, as seen in figure \ref{fig:shap}, that there is a clear difference between the original signals and the signals with artificially added noise. There is also a clear indication that the type of noise affects the resulting Shapley values. The point of highest variance is located in a different spot on the signals with Gaussian noise, compared to signals with zeroing. We can notice one very interesting behaviour from this, especially on the Gaussian noise signals. Interestingly, the peaks of the contribution of variance for the two noisy signals are both at the same location, which is noticeably different from the original signal. This similarity is unexpected. If the noise were to affect the contribution of the variance,  one would expect the peaks to be different for the signals with noise in the 0-250ms region and for signals in the 250-500ms region. This is not the case. Moreover, if the noise did not affect the variance, the peaks would be the same as the original signal, which is also not the case. This same behaviour is also noticed on the zeroed signal but less extreme. This behaviour suggests that noise affects the feature contribution to the variance, but not in the way initially expected.

Regardless of this unexpected behaviour, the main goal of this paper is to see whether the location of the noise can be found from the Shapley values. For both signals, the variance on the 0-250ms region is higher when there is noise added to this region. However, this variance is still lower than observed in the original signals. On the 250-500 ms region, there is no increase in variance, with even a decrease in variance for the zeroed signal. Adding noise in different regions has a very inconclusive effect on the Shapley values. 

Thus, one may notice from the Shapley values that a signal has been modified with artificial noise but cannot pinpoint the exact location of the source of uncertainty.

\subsection{Experimental setup issues}

As one may have noticed in this paper, the dataset consists of data from six participants. One may have also noticed that thus far, I have been training on the same participants (2-6) and testing on the same participant (1). This was done deliberately. EEG signals are prone to very high inter-participant variability. Due to this high variability and only having six participants, testing on all participants was not a viable choice due to the low consistency in results between participants. Due to this high variance, it was impossible to gather concise results, and the difference between training sessions is much larger than the already quite large difference experienced with only one test participant.

The two methods of generating artificial noise, Gaussian noise and the zeroing of channels, used for the experiments are only rough simulations of noise and could be more realistic. The noise used in these experiments, which showed results are magnitudes higher than in real-life applications. A more realistic approach would be adding noise variants that are more common in EEG signals. One such approach would be the recreation of physiological artefacts, such as the signals originating from the motor complex for actions like blinking. This method drastically increases the experiment's complexity and is way beyond the scope of this research paper, but it could be interesting to research in the future.

For this experiment, I focused on a single model: EEGNet, developed by \cite{lawhern2018eegnet}. This model is a compact Convolutional Neural Network (CNN). However, this is one of many model architectures commonly used for EEG classification. One of these architectures which is commonly used is the Recurrent Neural Network (RNN). It might be possible that the localization of the noise can be achieved when using the other architectures since they observe and train from the data in different ways, and thus can be interesting research for the future.
