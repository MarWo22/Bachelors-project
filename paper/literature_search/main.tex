\documentclass[10pt]{article}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{times}
\usepackage[a4paper]{geometry}

\title{{\bf Bachelor's Thesis} \\ Literature search}
\author{}
\date{\today}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\subsection*{Error perception classification in Brain-Computer Interfaces using CNN \cite{correia2021error}}

The main goal of this paper was to implement a CNN to predict error potentials which could be used for error-correction in Brain Computer Inerfaces (BCIâ€™s)
Error-related Potentials (ErrP) have been used to include the perception of subjects on errors caused by the BCIs
ErrP originate from the anterior cingulate cortex and is elicited as a response to error perception after a feedback presentation 
It used the publicly available dataset from the BNCI Horizon 2020 project website under the name Monitoring error-related potentials. The data was generated by subjects who monitored a moving cursor without controls. There was a 20% chance for the cursor to move the wrong way
Only preprocessing was a 1 to 10hz bandpass filter
All 64 channels were used. This gave better results than 2 selected channels (FCZ and FZ)

\subsection*{Estimating the Mean and Variance of the Target Probability Distribution \cite{nix1994estimating}}
The main aim of this paper is to develop a feed-forward network which can also predict it's uncertainty in a regression task. 
To achieve this, they created a network with two heads, each head having its individual hidden layers. They only share the input layer, 
without any shared hidden layers. For this particular task, it showed better performance. First, only the weights of the y-headed side 
(the actual regression task) were trained, and the $\sigma^2$ (Variance) head was ignored. The reasoning behind this is to reduce the computing load, since training the variance predictor does not make sense, 
if the actual regression task is nowhere near accurate. This paper was written in '91, so computing power was quite scarce. In this age, this step might not be necessary, since computing power is (usually)
 not extremely scarce anymore. Unless it has a serious effect on performance, which is unknown.

After the regression task has trained for a sufficient amount, and it progress is starting to flatten off, all weights are trained. Including the variance predictor weights. The weights are updated using the following equations:

Where n is the learning rate. Di is the true pattern, y(x) is the prediction, and s2 is the predicted variance. The aim of to adjust the weights of the this predictor to also predict this variance.
This paper is aimed for regression tasks, where there is a clear difference between the predicted continuous value and the actual continuous value. In a classification environment this becomes more challenging, since this clear difference is no more.

\subsection*{What uncertainties do we need in bayesian deep learning for computer vision \cite{kendall2017uncertainties}}

Deep learning models have two major types of uncertainty. The first one being epistemic uncertainty.
This is the uncertainty of the model parameters. This can often be explained away given enough data.
The other type is aleatoric uncertainty. This is noise inherent to the observations, such as faulty sensors.
The latter can be further categorized into homoscedastic uncertainty, which is constant regardles of the input,
and heteroscedastic uncertainty, which depends on the inputs. The latter sparks the most interest for my research topic.
These uncertainties can be modeled using Bayesian deep learning approaches.
To capture epistemic uncertainty in NNs a prior distribution is put over all weights, such as a Guassian distribution
These are called Bayesian Networks. To model this uncertainty, they try to capture how much these weights vary on the data.
For the aleatoric uncertainty, a distribution is placed over the output of the model, and then try to learn the noise's variance based of the inputs.


The paper suggests to use a single network with its head split to predicty both $\hat{y}$ and $\hat{\sigma}^2$
The model does need 'uncertainty labels' to learn the uncertainty. Instead, it infers it from the loss function during the regression task.
To make the model work for classification tasks there needs to be some adjustments. In their example, the model predicts a vector of unaries,
which, when passed through a softmax function, forms a probability vector. They place a Guassian distribution over this vector.
Then they approximate through Monte Carlo integration, and sample unaries through the softmax function.

All formulas and a better discription can be found in the paper in section 3. This section is almost too dense to properly summerize.

\subsection*{On the pitfalls of heteroscedastic uncertainty estimation with probabilistic neural networks \cite{seitzer2022pitfalls}}



\subsection*{Further possible readings}
\begin{itemize}
    \item Uncertainty quantification for multilabel text classification \cite{chen2020uncertainty}
    \item Uncertainty estimation in medical image classification: systematic review \cite{kurz2022uncertainty}
    \item BayesNetCNN: incorporating uncertainty in neural networks for image-based classification tasks \cite{ferrante2022bayesnetcnn}
    \item Confidence estimation methods for neural networks: A practical comparison \cite{papadopoulos2001confidence}
    \item Practical uncertainty quantification for brain tumor segmentation \cite{fuchs2021practical}
\end{itemize}


\bibliographystyle{plain} 
\bibliography{bibfile}

\end{document}