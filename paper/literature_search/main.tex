\documentclass[10pt]{article}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{times}
\usepackage[a4paper]{geometry}

\title{{\bf Bachelor's Thesis} \\ Literature search}
\author{}
\date{\today}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\subsection*{Error perception classification in Brain-Computer Interfaces using CNN \cite{correia2021error}}

The main goal of this paper was to implement a CNN to predict error potentials which could be used for error-correction in Brain Computer Inerfaces (BCI's).
Error-related Potentials (ErrP) have been used to include the perception of subjects on errors caused by these BCIs.
ErrPs originate from the anterior cingulate cortex and is elicited as a response to error perception after a feedback presentation 
It used the publicly available dataset from the BNCI Horizon 2020 project website under the name Monitoring error-related potentials. The data was generated by subjects who monitored a moving cursor without controls. There was a 20\% chance for the cursor to move the wrong way. 
The only preprocessing that done was a 1 to 10hz butterworth bandpass filter.
All 64 channels were used in windows of 600ms after the stimuli. This gave better results than 2 selected channels (FCZ and FZ).
They were able to achieve an accuracy of 80\%, 76\% sensitivy, and 85\% specificity. 

\subsection*{Estimating the Mean and Variance of the Target Probability Distribution \cite{nix1994estimating}}
The main aim of this paper is to develop a feed-forward network which can also predict it's uncertainty in a regression task. 
To achieve this, they created a network with two heads, each head having its individual hidden layers. They only share the input layer, 
without any shared hidden layers. For this particular task, it showed better performance. First, only the weights of the y-headed side 
(the actual regression task) were trained, and the $\sigma^2$ (Variance) head was ignored. The reasoning behind this is to reduce the computing load, since training the variance predictor does not make sense, 
if the actual regression task is nowhere near accurate.

This paper is aimed for regression tasks, where there is a clear difference between the predicted continuous value and the actual continuous value. In a classification environment this becomes more challenging, since this clear difference is no more.

\subsection*{What uncertainties do we need in bayesian deep learning for computer vision \cite{kendall2017uncertainties}}

Deep learning models have two major types of uncertainty. The first one being epistemic uncertainty.
This is the uncertainty of the model parameters. This can often be explained away given enough data.
The other type is aleatoric uncertainty. This is noise inherent to the observations, such as faulty sensors.
The latter can be further categorized into homoscedastic uncertainty, which is constant regardles of the input,
and heteroscedastic uncertainty, which depends on the inputs. The latter sparks the most interest for my research topic.
These uncertainties can be modeled using Bayesian deep learning approaches.
To capture epistemic uncertainty in NNs a prior distribution is put over all weights, such as a Guassian distribution
These are called Bayesian Networks. To model this uncertainty, they try to capture how much these weights vary on the data.
For the aleatoric uncertainty, a distribution is placed over the output of the model, and then try to learn the noise's variance based of the inputs.


The paper suggests to use a single network with its head split to predicty both $\hat{y}$ and $\hat{\sigma}^2$
The model does need 'uncertainty labels' to learn the uncertainty. Instead, it infers it from the loss function during the regression task.
To make the model work for classification tasks there needs to be some adjustments. In their example, the model predicts a vector of unaries,
which, when passed through a softmax function, forms a probability vector. They place a Guassian distribution over this vector.
Then they approximate through Monte Carlo integration, and sample unaries through the softmax function.

All formulas and a better discription can be found in the paper in section 3. This section is almost too dense to properly summerize.

\subsection*{On the pitfalls of heteroscedastic uncertainty estimation with probabilistic neural networks \cite{seitzer2022pitfalls}}

Typically, aleatoric uncertainty in regresion tasks can be predicted using a neural network to predict the parameters of the distribution, 
when assuming a heteroscedastic Gaussian distribution.
Usually, MLE (Maximum Log Likelihood) is used to learn, by minimizing the NLL (Negative Log Likelihood) using stochastic descent.
This method is pretty much de-facto, and was introduced by Nix\cite{nix1994estimating}
However, this method has a high dependence of the gradients on the predictive variance, and creates an instable model.
This paper suggest an alternative loss function $\beta-NLL$, which counteracts by weighting each data point's contributions to the overall loss by its $\beta$ estimate, 
which controls the dependency of gradients on the predictive variance. For the exact theory on how this works, refer back to the paper.

The GitHub repository contains an implementation of a neural net for a regression task which could be useful.

\subsection*{Uncertainty quantification for multilabel text classification \cite{chen2020uncertainty}}
They used Bayesian Networks for the quantification of aleatoric uncertainties in a multilabel text classification environment.
They mainly aimed at capturing the homoscedastic aleatoric uncertainty, which is constant across all inputs. In our case, we are mainly interested in capturing the heteroscedastic aleatoric uncertainty.

\subsection*{Uncertainty estimation in medical image classification: systematic review \cite{kurz2022uncertainty}}
Still working on it

\subsection*{Further possible readings}
\begin{itemize}
    \item BayesNetCNN: incorporating uncertainty in neural networks for image-based classification tasks \cite{ferrante2022bayesnetcnn}
    \item Confidence estimation methods for neural networks: A practical comparison \cite{papadopoulos2001confidence}
    \item Practical uncertainty quantification for brain tumor segmentation \cite{fuchs2021practical}
    \item Reliable multi-class classification based on pairwise epistemic and aleatoric uncertainty\cite{nguyen2018reliable}
\end{itemize}


\bibliographystyle{plain} 
\bibliography{bibfile}

\end{document}